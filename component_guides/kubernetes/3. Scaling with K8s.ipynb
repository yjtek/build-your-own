{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deployments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We have seen how to use standalone K8s pods\n",
    "- Now we'll see how to scale with K8s using deployments\n",
    "\n",
    "- Note that all pods within a single deployment will be exactly the same"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `kubectl create deployment nginx-deployment --image=nginx`\n",
    "    - Create deployment\n",
    "- `kubectl get deployments` / `kubectl get pods`\n",
    "    - Get deployment and pod details\n",
    "- `kubectl describe deployment nginx-deployment`\n",
    "    - Get details of created deployment\n",
    "    - You will see a **ReplicaSet** tagged to a deployment. What is this?\n",
    "        - ReplicaSet manages all pods related to deployment; simply a set of replicas of your application\n",
    "\n",
    "- `kubectl get pods`\n",
    "    - Notice that the name of the pod now starts with the name of the replicaset, followed by a specific hash for each pod\n",
    "\n",
    "- `kubectl describe pod nginx-deployment-c45d79c8-cmfws`\n",
    "    - Get single pod details\n",
    "\n",
    "- `kubectl scale deployment nginx-deployment --replicas=5`\n",
    "    - Create 4 new containers that duplicates your ealrier deployment\n",
    "\n",
    "- `kubectl get pods -o wide`\n",
    "    - See that each of your pods have a different IP address\n",
    "\n",
    "- `kubectl scale deployment nginx-deployment --replicas=3`\n",
    "    - Scale down to 3 replicas instead\n",
    "\n",
    "- `minikube ssh` + `curl 10.244.0.6`\n",
    "    - ssh into your kubernetes cluster, and curl the pod\n",
    "\n",
    "- So far, we've tried to connect to these pods via their IP addresses\n",
    "    - This is a terrible way of doing it, because obviously the allocated address changes every time\n",
    "    - In K8s cluster, it is possible to have multiple nodes, and pods can be distributed inside different nodes\n",
    "        - So trying to access using IP address, or even virtual IP addresses, is going to be a massive pain, because often IP addresses are private to the node\n",
    "        - So instead, the easier way is to have a load balancer IP address\n",
    "        - In this way, there is only 1 IP address for the whole K8s cluster for a deployment, and you can access your deployment with a single entry point\n",
    "        - Such load balancer IP address is usually assigned by specific cloud provider, which is controlled by `cloud controller manager` which runs on master node\n",
    "\n",
    "- `kubectl get deployments`\n",
    "\n",
    "- `kubectl expose deployment nginx-deployment --port=8080 --target-port=80`\n",
    "    - We create a service for this deployment\n",
    "    - Using this, we can expose a specific pod from the deployment \n",
    "    - by default, nginx runs on port 80, so we expose internal port 80 on the containers to any other pods outside of the deployment\n",
    "\n",
    "- `kubectl get services`\n",
    "    - Now, there are 2 services; one for the main K8s deployment, and the other for the nginx-deployment we just exposed\n",
    "    - Notice that the cluster IP address for the exposed deployment exists in another network, and can now be used to connect to any pod from inside the K8s cluster\n",
    "    - Note that this cluster IP address is accessible from within your K8s deployment (i.e. after you ssh), but not from the outside world\n",
    "\n",
    "- `minikube ssh` + `curl 10.105.236.114:8080`\n",
    "    - The curl will hit one of the pods in the deployment, but you won't know which exactly\n",
    "    - K8s will handle all load balancing to specific pods\n",
    "\n",
    "- `kubectl describe service nginx-deployment`"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
